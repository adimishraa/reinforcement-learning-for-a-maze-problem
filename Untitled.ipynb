{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Parameter files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=[]\n",
    "with open('rewards.txt','r') as file:\n",
    "    lines=file.readlines()\n",
    "rewards=[]\n",
    "for line in lines:\n",
    "    rewards.append(int(line[0:-1]))\n",
    "rewards=np.array(rewards).reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_matrix(filename):\n",
    "    lines=[]\n",
    "    with open(filename) as file:\n",
    "        lines=file.readlines()\n",
    "    prob=np.zeros((81,81))\n",
    "    for line in lines:\n",
    "        vals=line[0:-1].split('  ')\n",
    "        prob[int(vals[0])-1][int(vals[1])-1]=float(vals[2])\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 81, 4)\n"
     ]
    }
   ],
   "source": [
    "transition_a1=get_prob_matrix('prob_a1.txt')\n",
    "transition_a2=get_prob_matrix('prob_a2.txt')\n",
    "transition_a3=get_prob_matrix('prob_a3.txt')\n",
    "transition_a4=get_prob_matrix('prob_a4.txt')\n",
    "#act_trans=np.array()\n",
    "act_trans=np.concatenate((transition_a1.reshape((81,81,1)),transition_a2.reshape((81,81,1))),axis=2)\n",
    "act_trans=np.concatenate((act_trans,transition_a3.reshape((81,81,1))),axis=2)\n",
    "act_trans=np.concatenate((act_trans,transition_a4.reshape((81,81,1))),axis=2)\n",
    "print(np.shape(act_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma=0.9925\n",
    "policy=transition_a1\n",
    "vpi=np.matmul(np.linalg.inv(np.identity(81)-gamma*policy),rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_vector=np.array([0]*81)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_evaluation(gamma,policy,rewards):\n",
    "    return np.matmul(np.linalg.inv(np.identity(81)-gamma*policy),rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement(vpi,policy,act_trans,act_vector):\n",
    "    for i in range(0,vpi.shape[0]):\n",
    "        res_max=[]\n",
    "        for j in range(act_trans.shape[2]):\n",
    "           # print(act_trans[:,i,j].reshape((1,81)).shape)\n",
    "            res_max.append(np.matmul(act_trans[i,:,j],vpi))\n",
    "        amax=np.argmax(np.array(res_max))\n",
    "        #print(amax)\n",
    "        act_vector[i]=amax\n",
    "        policy[i,:]=act_trans[i,:,amax]\n",
    "    return policy,act_vector      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy,act_vector=policy_improvement(vpi,policy,act_trans,act_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma=0.9925\n",
    "policy=transition_a2\n",
    "def policy_iteration(gamma,act_trans,rewards,policy):\n",
    "    act_vector_new=np.array([1]*81)\n",
    "    act_vector=np.array([0]*81)\n",
    "    for i in range(0,100):\n",
    "        act_vector=act_vector_new\n",
    "        vpi=policy_evaluation(gamma,policy,rewards)\n",
    "        policy_new,act_vector_new=policy_improvement(vpi,policy,act_trans,act_vector)\n",
    "        policy=policy_new\n",
    "       # print(policy.shape)\n",
    "    return policy_evaluation(gamma,policy,rewards),act_vector_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_of_policy,act_vector=policy_iteration(gamma,act_trans,rewards,policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.            0.          100.70098073    0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "  102.3752644   101.52364515    0.            0.          109.48993454\n",
      "  110.40903296  111.33584663    0.            0.          103.23462342\n",
      "    0.          106.77826755  107.67462643  108.57848712    0.\n",
      "  112.27044032    0.            0.          104.10121204  104.97507555\n",
      "  105.88853591    0.            0.          114.1632295   113.21287932\n",
      "    0.            0.            0.          103.78140737    0.\n",
      "    0.            0.          115.12155727    0.            0.\n",
      "    0.         -133.33333333   90.9853796  -133.33333333    0.\n",
      " -133.33333333  116.08792959  122.02491241    0.            0.\n",
      "   81.39949278   93.67165583   95.17285726  108.34261934  109.58365072\n",
      "  123.64307021  123.1822391     0.            0.         -133.33333333\n",
      "   81.39949278 -133.33333333    0.         -133.33333333  125.24978944\n",
      "  124.20738563    0.            0.            0.            0.\n",
      "    0.            0.            0.          133.33333333    0.\n",
      "    0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(value_of_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 0 0 0 0 0 0 0 2 1 0 0 3 3 2 0 0 2 0 3 3 0 0 2 0 0 3 3 0 0 0 2 1 0 0\n",
      " 0 0 0 0 0 2 0 0 0 0 0 0 0 0 2 2 0 0 3 3 3 3 3 2 2 0 0 0 0 0 0 0 2 1 0 0 0\n",
      " 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(act_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Value function values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 100.70098072748917\n",
      "12 101.52364514898133\n",
      "11 102.37526440102096\n",
      "20 103.23462341601055\n",
      "29 104.10121204279739\n",
      "30 104.97507555494727\n",
      "31 105.88853590955105\n",
      "22 106.77826755022939\n",
      "23 107.6746264288036\n",
      "24 108.57848711681847\n",
      "15 109.48993453646312\n",
      "16 110.40903296181368\n",
      "17 111.33584663396846\n",
      "26 112.27044031794432\n",
      "35 113.212879322008\n",
      "34 114.16322950263664\n",
      "43 115.12155726913036\n",
      "52 116.08792958825303\n",
      "53 122.02491241481368\n",
      "61 123.64307020769664\n",
      "62 123.18223909953844\n",
      "70 125.24978943555789\n",
      "71 124.20738563339648\n",
      "39 103.78140737394398\n",
      "48 90.98537960093469\n",
      "57 93.67165583314663\n",
      "56 81.39949278128718\n",
      "66 81.39949278128718\n",
      "58 95.17285726464925\n",
      "59 108.34261934340633\n",
      "60 109.58365071834507\n"
     ]
    }
   ],
   "source": [
    "arglist=[2,11,10,19,28,29,30,21,22,23,14,15,16,25,34,33,42,51,52,60,61,69,70,38,47,56,55,65,57,58,59]\n",
    "for arg in arglist:\n",
    "    print(arg+1,value_of_policy[arg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 2 2 3 3 0 3 3 0 3 3 2 2 1 2 2 2 2 2 2 2 1 0 0 3 3 0 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "print(act_vector[arglist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Policy actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 'EAST')\n",
      "(12, 'NORTH')\n",
      "(11, 'EAST')\n",
      "(20, 'EAST')\n",
      "(29, 'SOUTH')\n",
      "(30, 'SOUTH')\n",
      "(31, 'WEST')\n",
      "(22, 'SOUTH')\n",
      "(23, 'SOUTH')\n",
      "(24, 'WEST')\n",
      "(15, 'SOUTH')\n",
      "(16, 'SOUTH')\n",
      "(17, 'EAST')\n",
      "(26, 'EAST')\n",
      "(35, 'NORTH')\n",
      "(34, 'EAST')\n",
      "(43, 'EAST')\n",
      "(52, 'EAST')\n",
      "(53, 'EAST')\n",
      "(61, 'EAST')\n",
      "(62, 'EAST')\n",
      "(70, 'EAST')\n",
      "(71, 'NORTH')\n",
      "(39, 'WEST')\n",
      "(48, 'WEST')\n",
      "(57, 'SOUTH')\n",
      "(56, 'SOUTH')\n",
      "(66, 'WEST')\n",
      "(58, 'SOUTH')\n",
      "(59, 'SOUTH')\n",
      "(60, 'SOUTH')\n"
     ]
    }
   ],
   "source": [
    "direction_dict={0:'WEST',1:'NORTH',2:'EAST',3:'SOUTH'}\n",
    "for arg in arglist:\n",
    "    print((arg+1,direction_dict[act_vector[arg]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vpi=np.array([0]*81).reshape((81,1))\n",
    "#vpi=rewards\n",
    "gamma=0.9925\n",
    "def value_improvement(gamma,act_trans,rewards,vpi):\n",
    "    vpi_next = np.copy(vpi)\n",
    "    for s in range(0,vpi.shape[0]):\n",
    "        res_max=[]\n",
    "        for a in range(act_trans.shape[2]):\n",
    "            #print(np.matmul(act_trans[i,:,j],vpi).shape)\n",
    "            ra = np.matmul(act_trans[s,:,a],vpi)\n",
    "            res_max.append(ra)\n",
    "            #print(s, a, ra)\n",
    "        max_result=max(res_max)\n",
    "        #print(res_max)\n",
    "        #print(s, max_result)\n",
    "        vpi_next[s]=rewards[s]+gamma*max_result\n",
    "        #print(abs(vpi_next[s] - vpi[s]), gamma * max_result)\n",
    "        #print(s, max(np.abs(vpi - vpi_next)))\n",
    "    return vpi_next\n",
    "        #policy[i,:]=act_trans[i,:,amax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(gamma,act_trans,rewards,vpi):\n",
    "    act_vector=np.array([0]*81).reshape((81,1))\n",
    "    for i in range(5000):\n",
    "        vpi_next=value_improvement(gamma,act_trans,rewards,vpi)\n",
    "        vpi=vpi_next\n",
    "        #print(vpi)\n",
    "    for i in range(0,vpi.shape[0]):\n",
    "        res_max=[]\n",
    "        for j in range(act_trans.shape[2]):\n",
    "            res_max.append(np.matmul(act_trans[i,:,j],vpi))\n",
    "        #amax=np.max(np.array(res_max))\n",
    "        armax=np.argmax(np.array(res_max))\n",
    "        #print(res_max)\n",
    "        #printprint(amax)\n",
    "        act_vector[i]=armax\n",
    "    return act_vector, vpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.        ,    0.        ,  100.70098073,    0.        ,\n",
       "          0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          0.        ,    0.        ,  102.3752644 ,  101.52364515,\n",
       "          0.        ,    0.        ,  109.48993454,  110.40903296,\n",
       "        111.33584663,    0.        ,    0.        ,  103.23462342,\n",
       "          0.        ,  106.77826755,  107.67462643,  108.57848712,\n",
       "          0.        ,  112.27044032,    0.        ,    0.        ,\n",
       "        104.10121204,  104.97507555,  105.88853591,    0.        ,\n",
       "          0.        ,  114.1632295 ,  113.21287932,    0.        ,\n",
       "          0.        ,    0.        ,  103.78140737,    0.        ,\n",
       "          0.        ,    0.        ,  115.12155727,    0.        ,\n",
       "          0.        ,    0.        , -133.33333333,   90.9853796 ,\n",
       "       -133.33333333,    0.        , -133.33333333,  116.08792959,\n",
       "        122.02491241,    0.        ,    0.        ,   81.39949278,\n",
       "         93.67165583,   95.17285726,  108.34261934,  109.58365072,\n",
       "        123.64307021,  123.1822391 ,    0.        ,    0.        ,\n",
       "       -133.33333333,   81.39949278, -133.33333333,    0.        ,\n",
       "       -133.33333333,  125.24978944,  124.20738563,    0.        ,\n",
       "          0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          0.        ,    0.        ,  133.33333333,    0.        ,\n",
       "          0.        ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rewards = rewards.astype('float')\n",
    "act_vector,vpi=value_iteration(gamma,act_trans,rewards,rewards)\n",
    "vpi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values after Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 100.70098072748772\n",
      "12 101.52364514897988\n",
      "11 102.3752644010195\n",
      "20 103.23462341600909\n",
      "29 104.10121204279591\n",
      "30 104.97507555494579\n",
      "31 105.88853590954959\n",
      "22 106.7782675502279\n",
      "23 107.6746264288021\n",
      "24 108.57848711681693\n",
      "15 109.48993453646155\n",
      "16 110.40903296181209\n",
      "17 111.33584663396687\n",
      "26 112.27044031794271\n",
      "35 113.21287932200639\n",
      "34 114.163229502635\n",
      "43 115.1215572691287\n",
      "52 116.08792958825138\n",
      "53 122.02491241481192\n",
      "61 123.6430702076949\n",
      "62 123.18223909953667\n",
      "70 125.24978943555614\n",
      "71 124.20738563339475\n",
      "39 103.78140737394249\n",
      "48 90.98537960093337\n",
      "57 93.67165583314525\n",
      "56 81.39949278128594\n",
      "66 81.39949278128594\n",
      "58 95.17285726464786\n",
      "59 108.34261934340479\n",
      "60 109.58365071834353\n"
     ]
    }
   ],
   "source": [
    "for arg in arglist:\n",
    "    print(arg+1, vpi[arg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actions after Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 'EAST')\n",
      "(12, 'NORTH')\n",
      "(11, 'EAST')\n",
      "(20, 'EAST')\n",
      "(29, 'SOUTH')\n",
      "(30, 'SOUTH')\n",
      "(31, 'WEST')\n",
      "(22, 'SOUTH')\n",
      "(23, 'SOUTH')\n",
      "(24, 'WEST')\n",
      "(15, 'SOUTH')\n",
      "(16, 'SOUTH')\n",
      "(17, 'EAST')\n",
      "(26, 'EAST')\n",
      "(35, 'NORTH')\n",
      "(34, 'EAST')\n",
      "(43, 'EAST')\n",
      "(52, 'EAST')\n",
      "(53, 'EAST')\n",
      "(61, 'EAST')\n",
      "(62, 'EAST')\n",
      "(70, 'EAST')\n",
      "(71, 'NORTH')\n",
      "(39, 'WEST')\n",
      "(48, 'WEST')\n",
      "(57, 'SOUTH')\n",
      "(56, 'SOUTH')\n",
      "(66, 'WEST')\n",
      "(58, 'SOUTH')\n",
      "(59, 'SOUTH')\n",
      "(60, 'SOUTH')\n"
     ]
    }
   ],
   "source": [
    "direction_dict={0:'WEST',1:'NORTH',2:'EAST',3:'SOUTH'}\n",
    "for arg in arglist:\n",
    "   # print(arg)\n",
    "    #print(act_vector[arg])\n",
    "    print((arg+1,direction_dict[int(act_vector[arg])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error in values between the values obtained from Value Iteration and Policy Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1.4495071809506044e-12\n",
      "12 1.4495071809506044e-12\n",
      "11 1.4495071809506044e-12\n",
      "20 1.4637180356658064e-12\n",
      "29 1.4779288903810084e-12\n",
      "30 1.4779288903810084e-12\n",
      "31 1.4637180356658064e-12\n",
      "22 1.4921397450962104e-12\n",
      "23 1.5063505998114124e-12\n",
      "24 1.5347723092418164e-12\n",
      "15 1.5774048733874224e-12\n",
      "16 1.5916157281026244e-12\n",
      "17 1.5916157281026244e-12\n",
      "26 1.6058265828178264e-12\n",
      "35 1.6200374375330284e-12\n",
      "34 1.6342482922482304e-12\n",
      "43 1.6626700016786344e-12\n",
      "52 1.6484591469634324e-12\n",
      "53 1.7621459846850485e-12\n",
      "61 1.7337242752546445e-12\n",
      "62 1.7621459846850485e-12\n",
      "70 1.7479351299698465e-12\n",
      "71 1.7337242752546445e-12\n",
      "39 1.4921397450962104e-12\n",
      "48 1.3216094885137863e-12\n",
      "57 1.3784529073745944e-12\n",
      "56 1.2363443602225743e-12\n",
      "66 1.2363443602225743e-12\n",
      "58 1.3926637620897964e-12\n",
      "59 1.5347723092418164e-12\n",
      "60 1.5347723092418164e-12\n"
     ]
    }
   ],
   "source": [
    "for arg in arglist:\n",
    "    print(arg+1, value_of_policy[arg]-vpi[arg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since the error between the values is in the order of 10^-12, shows that values for value iteration agree to those of policy iteration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
